{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "#import pytorch_lightning as pl\n",
    "import lightning.pytorch as pl\n",
    "import torchmetrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score, MulticlassF1Score\n",
    "from torchmetrics.classification.accuracy import Accuracy, BinaryAccuracy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "#import pytorch_lightning.callbacks.\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.lr_monitor import LearningRateMonitor\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from resnet1d import ResNet1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\n",
    "    \"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./saved_models/ConvNets/\"\n",
    "\n",
    "\n",
    "# Function for setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "task = 'multiclass'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест на работоспособность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test beat shape (1, 12, 500)\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_beat = np.load('./transformed_train/00269_hr_n1.npy')\n",
    "kernel_size = 16\n",
    "stride = 2\n",
    "n_block = 48\n",
    "downsample_gap = 6\n",
    "increasefilter_gap = 12\n",
    "model = ResNet1D(\n",
    "    in_channels=12, \n",
    "    base_filters=16, # 64 for ResNet1D, 352 for ResNeXt1D\n",
    "    kernel_size=16, \n",
    "    stride=2, \n",
    "    groups=1, \n",
    "    n_block=12, \n",
    "    n_classes=1) \n",
    "\n",
    "\n",
    "test_beat = test_beat.reshape((1,12,-1))\n",
    "test_y = torch.tensor([[1.]])\n",
    "criterion = nn.BCELoss()\n",
    "print(\"test beat shape\", test_beat.shape)\n",
    "res= model(torch.from_numpy(test_beat).float())\n",
    "print(res.shape)\n",
    "criterion(res, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DatasetECG(Dataset):\n",
    "    def __init__(self, annotations_file, signals_dir):\n",
    "        \"\"\"\n",
    "        annotantions_file - path to the annotations dataframe. \n",
    "                            First column should be name of the record, second - strat_fold then labels \n",
    "        \n",
    "        signals_dir - path to the directory with transformed signals\n",
    "        \"\"\"\n",
    "        self.signals_labels = pd.read_csv(annotations_file)\n",
    "        #self.signals_labels = self.signals_labels[self.signals_labels[\"норма\"] != 1]\n",
    "        self.signals_dir = signals_dir \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signals_path = os.path.join(self.signals_dir, self.signals_labels.iloc[idx, 0]+ \".npy\")\n",
    "        signal = np.load(signals_path).astype(np.float32)        \n",
    "\n",
    "        # iloc[idx, 2:] 2 is because first column is a record name\n",
    "        # label = \"\".join(self.signals_labels.iloc[idx, 2:].values.astype(str).tolist())\n",
    "        labels = torch.from_numpy(self.signals_labels.iloc[idx, 2:].values.astype(int)).float()\n",
    "        if(task=='multiclass'):\n",
    "            labels = labels.argmax()\n",
    "        # label = self.targets.index(label)\n",
    "        # encoded_label = torch.zeros(13)\n",
    "        # encoded_label[label] = 1\n",
    "        return signal, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetECG(\"./train_annotations.csv\", \"transformed_train\")\n",
    "val_dataset = DatasetECG(\"./val_annotations.csv\", \"transformed_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.05606591, -0.05565603, -0.05543435, ..., -0.04581553,\n",
       "         -0.04809224, -0.04959198],\n",
       "        [-0.05318296, -0.05444064, -0.05539297, ..., -0.01075439,\n",
       "         -0.01168965, -0.01218284],\n",
       "        [ 0.04188694,  0.03767771,  0.03148359, ..., -0.03136727,\n",
       "         -0.03054101, -0.03023535],\n",
       "        ...,\n",
       "        [-0.05976075, -0.05914703, -0.05953107, ...,  0.0147575 ,\n",
       "          0.01444543,  0.01367953],\n",
       "        [-0.05247324, -0.05187733, -0.0522306 , ...,  0.00850576,\n",
       "          0.00825855,  0.00801677],\n",
       "        [-0.03657978, -0.03619318, -0.03575838, ...,  0.01442953,\n",
       "          0.01458279,  0.01419923]], dtype=float32),\n",
       " tensor(6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True) #, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False) #, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Lightning_ResNet1D(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams, model_class=ResNet1D, task=\"MULTILABEL\"):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = model_class(**model_hparams)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        self.train_score = F1Score(task=task, num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.val_score = MulticlassF1Score(task=task, num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.test_score = F1Score(task=task, num_labels=model_hparams[\"n_classes\"], num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.val_acc = Accuracy(task=task, num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.train_acc = Accuracy(task=task, num_labels=model_hparams[\"n_classes\"], num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        \n",
    "\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 12, 500), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here\n",
    "            # for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer: \"{self.hparams.optimizer_name}\"'\n",
    "\n",
    "        # We will reduce the learning rate by 0.1 every milestone\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[35,65, 115, 150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        self.model.train()\n",
    "        imgs, labels = batch\n",
    "        labels = np.squeeze(labels)\n",
    "        preds = np.squeeze(self.model(imgs))\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        #if len(preds.shape) < 2:\n",
    "        # print(preds.shape, labels.shape)\n",
    "        if False:\n",
    "            preds = preds.argmax(axis=1)\n",
    "            labels = labels.to(torch.int).argmax(axis=1)\n",
    "            \n",
    "        self.train_acc(preds, labels.to(torch.int))\n",
    "\n",
    "        self.train_score(preds, labels.to(torch.int))\n",
    "        # print(preds, labels.to(torch.int))\n",
    "        # print(preds.argmax(axis=1), labels.to(torch.int).argmax(axis=1))\n",
    "        self.log(\"train_f1_score\", self.train_score)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss  \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.model.eval()\n",
    "        imgs, labels = batch\n",
    "        labels = np.squeeze(labels)\n",
    "        preds = np.squeeze(self.model(imgs))\n",
    "\n",
    "        #preds = preds.view(1, -1)\n",
    "        #labels = labels.view(1, -1)\n",
    "        # print(torch.round(preds, decimals=2))\n",
    "        #if len(preds.shape) < 2:\n",
    "        #    preds = preds.view(-1, 1, -1)\n",
    "        #    labels = labels.view(1, -1)\n",
    "        # print(torch.round(preds, decimals=2))\n",
    "        # print(torch.round(labels, decimals=2))\n",
    "        # print(preds)\n",
    "        # print(labels)\n",
    "        self.val_acc(preds, labels.to(torch.int))\n",
    "        # print(preds)\n",
    "        # print(labels)\n",
    "        # print(preds.shape, labels.shape)\n",
    "        # print(preds.argmax(axis=1), labels.to(torch.int).argmax(axis=1))\n",
    "        self.val_score(preds, labels.to(torch.int))\n",
    "        self.log(\"val_f1_score\", self.val_score)\n",
    "        self.log(\"val_acc\", self.val_acc)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        preds = np.squeeze(self(batch))\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model_class=ResNet1D,num_epochs=None, train_continue = True, save_name=None, pretrained_filename=\"\", model_hparams=None, optimizer_hparams=None, optimizer_name=None, task=None):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    curr_model_save_path = os.path.join(CHECKPOINT_PATH, save_name)\n",
    "    trainer = pl.Trainer(\n",
    "        check_val_every_n_epoch=2,\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),  # Where to save models\n",
    "        # We run on a single GPU (if possible)\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        # How many epochs to train for if no patience is set\n",
    "        max_epochs=num_epochs,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                mode=\"max\", monitor=\"val_f1_score\", save_top_k=2,\n",
    "            ), \n",
    "            EarlyStopping(monitor=\"val_f1_score\", mode=\"max\", patience=15),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],  # Log learning rate every epoch\n",
    "    ) \n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = Lightning_ResNet1D.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        if(pretrained_filename!=\"\"):\n",
    "            print(\"FAILED TO LOAD A MODEL\")\n",
    "            return\n",
    "        # L.seed_everything(42)  # To be reproducable\n",
    "        if train_continue:\n",
    "            default_root_dir = os.path.join(CHECKPOINT_PATH, save_name) \n",
    "            default_root_dir = os.path.join(default_root_dir, \"lightning_logs\")\n",
    "            continue_path = os.path.join(default_root_dir, os.listdir(default_root_dir)[-1])\n",
    "            continue_path = os.path.join(continue_path, \"checkpoints\")\n",
    "            continue_path = os.path.join(continue_path, os.listdir(continue_path)[-1])\n",
    "\n",
    "\n",
    "        model = Lightning_ResNet1D(model_name=model_name, model_class=model_class,model_hparams=model_hparams, \n",
    "                                   optimizer_hparams=optimizer_hparams, optimizer_name=optimizer_name, task=task)\n",
    "        if train_continue:\n",
    "            trainer.fit(model, train_loader, val_loader, ckpt_path=continue_path)\n",
    "        else:\n",
    "            trainer.fit(model, train_loader, val_loader,)\n",
    "        model = Lightning_ResNet1D.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )  # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.validate(model, dataloaders=val_loader, verbose=False)\n",
    "    result = {\"val_acc\": val_result[0][\"val_acc\"], \"val_f1_score\": val_result[0][\"val_f1_score\"]}\n",
    "    \n",
    "    \n",
    "    return model, result, curr_model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at saved_models/ConvNets/Final_fixed_val_added_norm/lightning_logs/version_0/checkpoints/epoch=31-step=65824.ckpt, loading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ba2b6df36f42fca2d26f6f82e98b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# pretrained_filename=\"saved_models/ConvNets/ResNet1D_denoising_level2/lightning_logs/version_3/checkpoints/epoch=63-step=23104.ckpt\",     \n",
    "#удалить аргумент pretrained filename, для тренировки заново\n",
    "resnet_model, resnet_results, curr_model_save_path = train_model(\n",
    "    train_continue=False,\n",
    "    num_epochs=40,\n",
    "    pretrained_filename=\"saved_models/ConvNets/Final_fixed_val_added_norm/lightning_logs/version_0/checkpoints/epoch=31-step=65824.ckpt\",     \n",
    "    model_name=\"ResNet1D_v2\",\n",
    "    model_class=ResNet1D,\n",
    "    save_name=\"Final_fixed_val_added_norm\", \n",
    "    model_hparams={\"n_classes\": 7, \"base_filters\": 16, \"kernel_size\": 16, \"stride\": 2, \"groups\": 1, \"n_block\": 12, \"in_channels\": 12},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 0.0001,  \"weight_decay\": 1e-4},\n",
    "    task=\"multiclass\"\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_acc': 0.660504937171936, 'val_f1_score': 0.38577789068222046}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import mode\n",
    "\n",
    "resnet_model.eval()\n",
    "\n",
    "def predict(beat_filename):\n",
    "    test_beat = np.load(beat_filename).astype(np.float32) \n",
    "    test_beat = test_beat.reshape((1,12,-1))\n",
    "    res = resnet_model(torch.from_numpy(test_beat).float())\n",
    "    return res.detach().numpy()\n",
    "\n",
    "def run_test_predicts(curr_model_save_path, treshhold=0.5):\n",
    "    df_og = pd.read_csv(\"./train/train_meta.csv\")\n",
    "    test_annotations = pd.read_csv(\"./val_annotations.csv\")\n",
    "    test_annotations.drop_duplicates(inplace=True)\n",
    "    preds = {}\n",
    "    for name in tqdm(test_annotations[\"new_name\"]):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        pred = np.argmax(predict(\"./transformed_train/\"+name+\".npy\"))\n",
    "        preds[record_name].append(pred)\n",
    "\n",
    "    preds_most_freq = {}\n",
    "    for name, preds in preds.items(): \n",
    "        most_freq_pred = np.argmax(np.bincount(preds))   \n",
    "        preds_most_freq[name] = most_freq_pred\n",
    "\n",
    "    df_og[\"predict\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "    return df_og, preds_most_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f61f221ebc04ae589812574cbe57863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_res, d = run_test_predicts(curr_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>record_name</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18792.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>00009_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20961.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>00081_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11810.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>00108_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21312.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>00109_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20766.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00172_hr</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>10108.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21594_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>20615.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21601_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>10139.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21614_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>9234.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21617_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>18782.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21756_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id    age  sex  height  weight record_name  predict\n",
       "0        18792.0   55.0    0     NaN    70.0    00009_hr      6.0\n",
       "6        20961.0   46.0    1     NaN    47.0    00081_hr      6.0\n",
       "8        11810.0  300.0    1     NaN    57.0    00108_hr      6.0\n",
       "9        21312.0   18.0    1     NaN    73.0    00109_hr      6.0\n",
       "19       20766.0   62.0    0     NaN     NaN    00172_hr      0.0\n",
       "...          ...    ...  ...     ...     ...         ...      ...\n",
       "2074     10108.0   87.0    0     NaN     NaN    21594_hr      6.0\n",
       "2075     20615.0   56.0    0     NaN     NaN    21601_hr      6.0\n",
       "2077     10139.0   70.0    0     NaN     NaN    21614_hr      6.0\n",
       "2078      9234.0   72.0    0     NaN     NaN    21617_hr      6.0\n",
       "2093     18782.0   67.0    1     NaN     NaN    21756_hr      6.0\n",
       "\n",
       "[414 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res = test_res[~test_res.predict.isna()]\n",
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>норма</th>\n",
       "      <th>перегородочный</th>\n",
       "      <th>нижний</th>\n",
       "      <th>передне-перегородочный</th>\n",
       "      <th>передне-боковой</th>\n",
       "      <th>передний</th>\n",
       "      <th>боковой</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     норма  перегородочный  нижний  передне-перегородочный  передне-боковой  \\\n",
       "0        1               0       0                       0                0   \n",
       "1        1               0       0                       0                0   \n",
       "2        1               0       0                       0                0   \n",
       "3        1               0       0                       0                0   \n",
       "4        0               1       0                       0                0   \n",
       "..     ...             ...     ...                     ...              ...   \n",
       "409      1               0       0                       0                0   \n",
       "410      1               0       0                       0                0   \n",
       "411      1               0       0                       0                0   \n",
       "412      1               0       0                       0                0   \n",
       "413      1               0       0                       0                0   \n",
       "\n",
       "     передний  боковой  \n",
       "0           0        0  \n",
       "1           0        0  \n",
       "2           0        0  \n",
       "3           0        0  \n",
       "4           0        0  \n",
       "..        ...      ...  \n",
       "409         0        0  \n",
       "410         0        0  \n",
       "411         0        0  \n",
       "412         0        0  \n",
       "413         0        0  \n",
       "\n",
       "[414 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = pd.DataFrame(test_res.predict.tolist())\n",
    "\n",
    "label2pred = {\"перегородочный\":0, \"передний\":1, \"боковой\":2, \"передне-боковой\":3, \"передне-перегородочный\":4, \"нижний\":5, \"норма\":6}\n",
    "pred2label = {v:k for k, v in label2pred.items()}\n",
    "\n",
    "unique_values = predicts[0].unique() \n",
    "unique_values = np.append(unique_values, 2)\n",
    "for value in unique_values:\n",
    "    column_name = pred2label[value]\n",
    "    predicts[column_name] = (predicts[0] == value).astype(int)\n",
    "predicts = predicts.drop(columns=[0])\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_annotations = pd.read_csv(\"./train/train_gts_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res2 = test_res.merge(val_annotations, on=\"record_name\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>record_name</th>\n",
       "      <th>predict</th>\n",
       "      <th>перегородочный</th>\n",
       "      <th>передний</th>\n",
       "      <th>боковой</th>\n",
       "      <th>передне-боковой</th>\n",
       "      <th>передне-перегородочный</th>\n",
       "      <th>нижний</th>\n",
       "      <th>норма</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18792.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>00009_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20961.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>00081_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11810.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>00108_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21312.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>00109_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20766.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00172_hr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>10108.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21594_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>20615.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21601_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>10139.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21614_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9234.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21617_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>18782.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21756_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id    age  sex  height  weight record_name  predict  \\\n",
       "0       18792.0   55.0    0     NaN    70.0    00009_hr      6.0   \n",
       "1       20961.0   46.0    1     NaN    47.0    00081_hr      6.0   \n",
       "2       11810.0  300.0    1     NaN    57.0    00108_hr      6.0   \n",
       "3       21312.0   18.0    1     NaN    73.0    00109_hr      6.0   \n",
       "4       20766.0   62.0    0     NaN     NaN    00172_hr      0.0   \n",
       "..          ...    ...  ...     ...     ...         ...      ...   \n",
       "409     10108.0   87.0    0     NaN     NaN    21594_hr      6.0   \n",
       "410     20615.0   56.0    0     NaN     NaN    21601_hr      6.0   \n",
       "411     10139.0   70.0    0     NaN     NaN    21614_hr      6.0   \n",
       "412      9234.0   72.0    0     NaN     NaN    21617_hr      6.0   \n",
       "413     18782.0   67.0    1     NaN     NaN    21756_hr      6.0   \n",
       "\n",
       "     перегородочный  передний  боковой  передне-боковой  \\\n",
       "0                 0         0        0                0   \n",
       "1                 0         0        0                0   \n",
       "2                 0         0        0                0   \n",
       "3                 0         0        0                0   \n",
       "4                 0         0        0                0   \n",
       "..              ...       ...      ...              ...   \n",
       "409               0         0        0                0   \n",
       "410               0         0        0                0   \n",
       "411               0         0        0                0   \n",
       "412               0         0        0                0   \n",
       "413               0         0        0                0   \n",
       "\n",
       "     передне-перегородочный  нижний  норма  \n",
       "0                         0       0      1  \n",
       "1                         0       0      1  \n",
       "2                         0       0      1  \n",
       "3                         0       0      1  \n",
       "4                         0       0      1  \n",
       "..                      ...     ...    ...  \n",
       "409                       0       0      1  \n",
       "410                       0       0      1  \n",
       "411                       0       0      1  \n",
       "412                       0       0      1  \n",
       "413                       0       0      1  \n",
       "\n",
       "[414 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "перегородочный F1 0.1702127659574468\n",
      "передний F1 0.41666666666666663\n",
      "боковой F1 0.0\n",
      "передне-боковой F1 0.36363636363636365\n",
      "передне-перегородочный F1 0.3448275862068966\n",
      "нижний F1 0.4470588235294118\n",
      "норма F1 0.8529886914378028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('TOTAL', 0.37077012820494115)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "summs = 0\n",
    "for i, column in enumerate([\"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\", \"норма\"]):\n",
    "    print(column, \"F1\", f1_score(test_res2[column], predicts[column]))\n",
    "    summs += f1_score(test_res2[column], predicts[column])\n",
    "\"TOTAL\", summs / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_name                  03329_hr_n708985_hr_n202681_hr_n704819_hr_n608...\n",
       "target                                                               103649\n",
       "перегородочный                                                       5483.0\n",
       "передний                                                             5483.0\n",
       "боковой                                                                 0.0\n",
       "передне-боковой                                                      5483.0\n",
       "передне-перегородочный                                               5483.0\n",
       "нижний                                                               5483.0\n",
       "норма                                                                  5483\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./train_annotations.csv\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_res[~test_res.predict.isna()][\"predict\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict тренировочных данных и тестовых данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import mode\n",
    "\n",
    "resnet_model.eval()\n",
    "\n",
    "def predict(beat_filename):\n",
    "    test_beat = np.load(beat_filename).astype(np.float32) \n",
    "    test_beat = test_beat.reshape((1,12,-1))\n",
    "    res = resnet_model(torch.from_numpy(test_beat).float())\n",
    "    return res.detach().numpy()\n",
    "\n",
    "def run_test_predicts(curr_model_save_path):\n",
    "    df_og = pd.read_csv(\"./test/test_meta.csv\")\n",
    "    test_annotations = pd.read_csv(\"./transformed_test_df.csv\")\n",
    "    preds = {}\n",
    "    for name in tqdm(test_annotations[\"new_name\"].values):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        pred = np.argmax(predict(\"./transformed_test/\"+name+\".npy\"))\n",
    "        preds[record_name].append(pred)\n",
    "    \n",
    "    preds_most_freq = {}\n",
    "    for name, preds in preds.items(): \n",
    "        most_freq_pred = np.argmax(np.bincount(preds))   \n",
    "        preds_most_freq[name] = most_freq_pred\n",
    "\n",
    "    df_og[\"predict\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "\n",
    "    #print(np.round(np.array(preds[\"00127_hr\"]).mean(axis=0), 2))\n",
    "    #preds_median = {k: np.array(v).mean(axis=0) > 0.5 for k,v in preds.items()}\n",
    "    #df_og[\"predict\"] = df_og[\"record_name\"].map(preds_median)\n",
    "    label2pred = {\"перегородочный\":0, \"передний\":1, \"боковой\":2, \"передне-боковой\":3, \"передне-перегородочный\":4, \"нижний\":5, \"норма\":6}\n",
    "    pred2label = {v:k for k, v in label2pred.items()}\n",
    "    \n",
    "    unique_values = df_og['predict'].unique() \n",
    "    unique_values = np.append(unique_values, 2)\n",
    "    for value in unique_values:\n",
    "        column_name = pred2label[value]\n",
    "        df_og[column_name] = (df_og['predict'] == value).astype(int)\n",
    "\n",
    "    #preds_median = {k: np.array(v).mean(axis=0).argmax() for k,v in preds.items()}\n",
    "    df_og[\"target\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "    \n",
    "    save_path = os.path.join(curr_model_save_path, \"predicted_test.csv\")\n",
    "    df_og.to_csv(save_path)\n",
    "    df_og.to_csv(\"./predicted_test.csv\")\n",
    "    print(\"Соотношение предсказанных классов:\")\n",
    "    display(df_og['target'].apply(round).value_counts(normalize=True))\n",
    "    return df_og\n",
    "\n",
    "def preds_train_df(curr_model_save_path):\n",
    "    df = pd.read_csv(\"./transformed_df.csv\")\n",
    "    preds = {}\n",
    "    for name in tqdm(df[\"new_name\"].values):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        preds[record_name].append(predict(\"./transformed_train/\"+name+\".npy\"))\n",
    "    \n",
    "    df_og = pd.read_csv(\"../task_final/train/train_gts_final.csv\")\n",
    "    \n",
    "    preds_median = {k:np.median(np.array(v)) for k,v in preds.items()}\n",
    "    df_og['predict'] = df_og[\"record_name\"].map(preds_median)\n",
    "    save_path = os.path.join(curr_model_save_path, \"predicted_train.csv\")\n",
    "    df_og.to_csv(save_path)\n",
    "    df_og.to_csv(\"./predicted_train.csv\")\n",
    "    print(\"Соотношение предсказанных классов:\")\n",
    "    display(df_og['predict'].apply(round).value_counts(normalize=True))\n",
    "    return preds, df_og\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_submit = pd.read_csv(\"old_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcd83005fc64cd29c7a6db2ccb0892a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение предсказанных классов:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6    0.650334\n",
       "5    0.124722\n",
       "0    0.095768\n",
       "4    0.080178\n",
       "3    0.031180\n",
       "1    0.017817\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_res = run_test_predicts(curr_model_save_path)\n",
    "# preds, df_og = preds_train_df(curr_model_save_path)\n",
    "\n",
    "one_hot_enc = np.zeros((449, 6))\n",
    "for i in range(449):\n",
    "    one_hot_enc[i] = test_res[\"predict\"].iloc[i] * 1 + [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_enc = np.zeros((449, 6))\n",
    "for i in range(449):\n",
    "    one_hot_enc[i] = test_res[\"predict\"].iloc[i] * 1 + [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6., 6., 6., 6., 6.],\n",
       "       [6., 6., 6., 6., 6., 6.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [3., 3., 3., 3., 3., 3.],\n",
       "       [6., 6., 6., 6., 6., 6.],\n",
       "       [6., 6., 6., 6., 6., 6.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test_res[[\"перегородочный\",\"передний\",\"боковой\",\"передне-боковой\",\"передне-перегородочный\",\"нижний\",\"норма\",\"record_name\"]]\n",
    "#submit = pd.read_csv('saved_models/ConvNets/two_models/submit.csv')\n",
    "sample = pd.read_csv(\"./sample.csv\")\n",
    "submit = sample.merge(submit, on=\"record_name\", how=\"left\")\n",
    "submit = submit[[\"record_name\", \"перегородочный\",\"передний\",\"боковой\",\"передне-боковой\",\"передне-перегородочный\",\"нижний\",\"норма\"]]\n",
    "submit.to_csv(\"./saved_models/ConvNets/two_models/submit_fixed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'old_submit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb Cell 35\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m onehot_df[\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_res[\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m subm_df \u001b[39m=\u001b[39m test_res\u001b[39m.\u001b[39mmerge(onehot_df, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m subm_df \u001b[39m=\u001b[39m subm_df\u001b[39m.\u001b[39mmerge(old_submit, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m subm_df[\u001b[39m\"\u001b[39m\u001b[39mнорма\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m subm_df[\u001b[39m\"\u001b[39m\u001b[39mmyocard\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mперегородочный\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mпередний\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mбоковой\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mпередне-боковой\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mпередне-перегородочный\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mнижний\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'old_submit' is not defined"
     ]
    }
   ],
   "source": [
    "onehot_df = pd.DataFrame(one_hot_enc, columns=[\"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\"])\n",
    "onehot_df[\"record_name\"] = test_res[\"record_name\"]\n",
    "subm_df = test_res.merge(onehot_df, on=\"record_name\", how=\"left\")\n",
    "subm_df = subm_df.merge(old_submit, on=\"record_name\", how=\"left\")\n",
    "subm_df[\"норма\"] = subm_df[\"myocard\"].map(lambda x: 0 if x == 1 else 1)\n",
    "for column in [\"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\"]:\n",
    "    subm_df[column] = subm_df['myocard'] & subm_df[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df[[\"record_name\", \"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\", \"норма\"]].to_csv(\"submit.csv\", index=False)\n",
    "subm_df[[\"record_name\", \"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\", \"норма\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание всех тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean = {k:(sum(v)/len(v)) for k,v in preds.items()}\n",
    "preds_median = {k:np.median(np.array(v)) for k,v in preds.items()}\n",
    "preds_max= {k:np.argmax(np.array(v)) for k,v in preds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(preds, df_og):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "\n",
    "    for k, v in preds.items():\n",
    "        predicted_class = round(v)\n",
    "        actual_class = df_og[df_og[\"record_name\"] == k][\"myocard\"].values[0]\n",
    "        \n",
    "        if actual_class == 1 and predicted_class == 1:\n",
    "            tp += 1\n",
    "        elif actual_class == 0 and predicted_class == 0:\n",
    "            tn += 1\n",
    "        elif actual_class == 0 and predicted_class == 1:\n",
    "            fp += 1\n",
    "        elif actual_class == 1 and predicted_class == 0:\n",
    "            fn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    print(\"accuracy\", (tp + tn)/len(preds))\n",
    "    print(\"true positive rate, recall\", (tp/(tp+fn)))\n",
    "    print(\"true negative rate\", tnr)\n",
    "    print(\"f1_score\", 2*(precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(preds_mean, df_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(preds_median, df_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(preds_max, df_og)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
