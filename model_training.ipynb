{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import torchmetrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from torchmetrics.classification.accuracy import BinaryAccuracy\n",
    "import lightning as L\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.lr_monitor import LearningRateMonitor\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from resnet1d import ResNet1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\n",
    "    \"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./saved_models/ConvNets/\"\n",
    "\n",
    "\n",
    "# Function for setting the seed\n",
    "L.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест на работоспособность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test beat shape (1, 12, 500)\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8206, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_beat = np.load('./transformed_train/00269_hr_n1.npy')\n",
    "kernel_size = 16\n",
    "stride = 2\n",
    "n_block = 48\n",
    "downsample_gap = 6\n",
    "increasefilter_gap = 12\n",
    "model = ResNet1D(\n",
    "    in_channels=12, \n",
    "    base_filters=16, # 64 for ResNet1D, 352 for ResNeXt1D\n",
    "    kernel_size=16, \n",
    "    stride=2, \n",
    "    groups=1, \n",
    "    n_block=12, \n",
    "    n_classes=1) \n",
    "\n",
    "\n",
    "test_beat = test_beat.reshape((1,12,-1))\n",
    "test_y = torch.tensor([[1.]])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(\"test beat shape\", test_beat.shape)\n",
    "res= model(torch.from_numpy(test_beat).float())\n",
    "print(res.shape)\n",
    "criterion(res, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DatasetECG(Dataset):\n",
    "    def __init__(self, annotations_file, signals_dir):\n",
    "        \"\"\"\n",
    "        annotantions_file - path to the annotations dataframe. \n",
    "                            First column should be name of the record, second - strat_fold then labels \n",
    "        \n",
    "        signals_dir - path to the directory with transformed signals\n",
    "        \"\"\"\n",
    "        self.signals_labels = pd.read_csv(annotations_file)\n",
    "        self.signals_dir = signals_dir \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signals_path = os.path.join(self.signals_dir, self.signals_labels.iloc[idx, 0]+ \".npy\")\n",
    "        signal = np.load(signals_path).astype(np.float32)        \n",
    "\n",
    "        # iloc[idx, 2:] 2 is because first column is a record name\n",
    "        labels = torch.from_numpy(self.signals_labels.iloc[idx, 2:].values.astype(int)).float()\n",
    "        return signal, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetECG(\"./train_annotations.csv\", \"transformed_train\")\n",
    "val_dataset = DatasetECG(\"./val_annotations.csv\", \"transformed_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lightning_ResNet1D(L.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = ResNet1D(**model_hparams)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.BCEWithLogitsLoss()\n",
    "        self.train_score = BinaryF1Score()\n",
    "        self.val_score = BinaryF1Score()\n",
    "        self.test_score = BinaryF1Score()\n",
    "        self.val_acc = BinaryAccuracy()\n",
    "        self.train_acc = BinaryAccuracy()\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 12, 500), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here\n",
    "            # for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer: \"{self.hparams.optimizer_name}\"'\n",
    "\n",
    "        # We will reduce the learning rate by 0.1 every milestone\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[35,65, 115, 150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        imgs, labels = batch\n",
    "        labels = np.squeeze(labels)\n",
    "        preds = np.squeeze(self.model(imgs))\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        self.train_acc(preds, np.squeeze(labels).to(torch.int))\n",
    "\n",
    "        self.train_score(preds, labels.to(torch.int))\n",
    "        self.log(\"train_f1_score\", self.train_score)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss  \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        labels = np.squeeze(labels)\n",
    "        preds = np.squeeze(self.model(imgs))\n",
    "        self.val_acc(preds, labels.to(torch.int))\n",
    "        self.val_score(preds, labels.to(torch.int))\n",
    "        self.log(\"val_f1_score\", self.val_score)\n",
    "        self.log(\"val_acc\", self.val_acc)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        preds = np.squeeze(self(batch))\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, train_continue = True, save_name=None, pretrained_filename=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    curr_model_save_path = os.path.join(CHECKPOINT_PATH, save_name)\n",
    "    trainer = L.Trainer(\n",
    "        check_val_every_n_epoch=2,\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),  # Where to save models\n",
    "        # We run on a single GPU (if possible)\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        # How many epochs to train for if no patience is set\n",
    "        max_epochs=180,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                mode=\"max\", monitor=\"val_f1_score\", save_top_k=2,\n",
    "            ), \n",
    "            EarlyStopping(monitor=\"val_f1_score\", mode=\"max\", patience=15),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],  # Log learning rate every epoch\n",
    "    ) \n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = Lightning_ResNet1D.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        if(pretrained_filename!=\"\"):\n",
    "            print(\"FAILED TO LOAD A MODEL\")\n",
    "            return\n",
    "        L.seed_everything(42)  # To be reproducable\n",
    "        if train_continue:\n",
    "            default_root_dir = os.path.join(CHECKPOINT_PATH, save_name) \n",
    "            default_root_dir = os.path.join(default_root_dir, \"lightning_logs\")\n",
    "            continue_path = os.path.join(default_root_dir, os.listdir(default_root_dir)[-1])\n",
    "            continue_path = os.path.join(continue_path, \"checkpoints\")\n",
    "            continue_path = os.path.join(continue_path, os.listdir(continue_path)[-1])\n",
    "\n",
    "\n",
    "        model = Lightning_ResNet1D(model_name=model_name, **kwargs)\n",
    "        if train_continue:\n",
    "            trainer.fit(model, train_loader, val_loader, ckpt_path=continue_path)\n",
    "        else:\n",
    "            trainer.fit(model, train_loader, val_loader,)\n",
    "        model = Lightning_ResNet1D.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )  # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.validate(model, dataloaders=val_loader, verbose=False)\n",
    "    result = {\"val_acc\": val_result[0][\"val_acc\"], \"val_f1_score\": val_result[0][\"val_f1_score\"]}\n",
    "    \n",
    "    \n",
    "    return model, result, curr_model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at saved_models/ConvNets/ResNet1D_denoising_level2/lightning_logs/version_3/checkpoints/epoch=63-step=23104.ckpt, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94e7c6687b54a89b2f17266afed0e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#удалить аргумент pretrained filename, для тренировки заново\n",
    "resnet_model, resnet_results, curr_model_save_path = train_model(\n",
    "    train_continue=False,\n",
    "    pretrained_filename=\"saved_models/ConvNets/ResNet1D_denoising_level2/lightning_logs/version_3/checkpoints/epoch=63-step=23104.ckpt\",     \n",
    "    model_name=\"ResNet1D\",\n",
    "    save_name=\"ResNet1D_denoising_level2\", \n",
    "    model_hparams={\"n_classes\": 1, \"base_filters\": 16, \"kernel_size\":16, \"stride\":2, \"groups\":1, \"n_block\":12, \"in_channels\":12},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 0.0001,  \"weight_decay\": 1e-4},\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_acc': 0.8058419227600098, 'val_f1_score': 0.8253477811813354}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict тренировочных данных и тестовых данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "resnet_model.eval()\n",
    "\n",
    "def predict(beat_filename):\n",
    "    test_beat = np.load(beat_filename).astype(np.float32) \n",
    "    test_beat = test_beat.reshape((1,12,-1))\n",
    "    res = resnet_model(torch.from_numpy(test_beat).float())\n",
    "    return torch.sigmoid(res).item()\n",
    "\n",
    "def run_test_predicts(curr_model_save_path):\n",
    "    df_og = pd.read_csv(\"./test/test_meta.csv\")\n",
    "    test_annotations = pd.read_csv(\"./transformed_test_df.csv\")\n",
    "    preds = {}\n",
    "    for name in tqdm(test_annotations[\"new_name\"].values):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        preds[record_name].append(predict(\"./transformed_test/\"+name+\".npy\"))\n",
    "    \n",
    "    \n",
    "    preds_median = {k:np.median(np.array(v)) for k,v in preds.items()}\n",
    "    df_og[\"predict\"] = df_og[\"record_name\"].map(preds_median)\n",
    "    save_path = os.path.join(curr_model_save_path, \"predicted_test.csv\")\n",
    "    df_og.to_csv(save_path)\n",
    "    df_og.to_csv(\"./predicted_test.csv\")\n",
    "    print(\"Соотношение предсказанных классов:\")\n",
    "    display(df_og['predict'].apply(round).value_counts(normalize=True))\n",
    "    return df_og\n",
    "\n",
    "def preds_train_df(curr_model_save_path):\n",
    "    df = pd.read_csv(\"./transformed_df.csv\")\n",
    "    preds = {}\n",
    "    for name in tqdm(df[\"new_name\"].values):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        preds[record_name].append(predict(\"./transformed_train/\"+name+\".npy\"))\n",
    "    \n",
    "    df_og = pd.read_csv(\"./train/train_gts.csv\")\n",
    "    \n",
    "    preds_median = {k:np.median(np.array(v)) for k,v in preds.items()}\n",
    "    df_og['predict'] = df_og[\"record_name\"].map(preds_median)\n",
    "    save_path = os.path.join(curr_model_save_path, \"predicted_train.csv\")\n",
    "    df_og.to_csv(save_path)\n",
    "    df_og.to_csv(\"./predicted_train.csv\")\n",
    "    print(\"Соотношение предсказанных классов:\")\n",
    "    display(df_og['predict'].apply(round).value_counts(normalize=True))\n",
    "    return preds, df_og\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d44079f463c409097f0421b05e3e62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение предсказанных классов:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.612472\n",
       "1    0.387528\n",
       "Name: predict, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a87d6da79ca4dc39d1bac855c6e7f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение предсказанных классов:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.603046\n",
       "1    0.396954\n",
       "Name: predict, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_res = run_test_predicts(curr_model_save_path)\n",
    "preds, df_og = preds_train_df(curr_model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание всех тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean = {k:(sum(v)/len(v)) for k,v in preds.items()}\n",
    "preds_median = {k:np.median(np.array(v)) for k,v in preds.items()}\n",
    "preds_max= {k:np.argmax(np.array(v)) for k,v in preds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(preds, df_og):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "\n",
    "    for k, v in preds.items():\n",
    "        predicted_class = round(v)\n",
    "        actual_class = df_og[df_og[\"record_name\"] == k][\"myocard\"].values[0]\n",
    "        \n",
    "        if actual_class == 1 and predicted_class == 1:\n",
    "            tp += 1\n",
    "        elif actual_class == 0 and predicted_class == 0:\n",
    "            tn += 1\n",
    "        elif actual_class == 0 and predicted_class == 1:\n",
    "            fp += 1\n",
    "        elif actual_class == 1 and predicted_class == 0:\n",
    "            fn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    print(\"accuracy\", (tp + tn)/len(preds))\n",
    "    print(\"true positive rate, recall\", (tp/(tp+fn)))\n",
    "    print(\"true negative rate\", tnr)\n",
    "    print(\"f1_score\", 2*(precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7877201332698714\n",
      "true positive rate, recall 0.9783132530120482\n",
      "true negative rate 0.7408066429418743\n",
      "f1_score 0.6454689984101748\n"
     ]
    }
   ],
   "source": [
    "check(preds_mean, df_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7910518800571157\n",
      "true positive rate, recall 0.9759036144578314\n",
      "true negative rate 0.7455516014234875\n",
      "f1_score 0.6485188150520417\n"
     ]
    }
   ],
   "source": [
    "check(preds_median, df_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2527367920038077\n",
      "true positive rate, recall 0.390625\n",
      "true negative rate 0.7042459736456809\n",
      "f1_score 0.26315789473684215\n"
     ]
    }
   ],
   "source": [
    "check(preds_max, df_og)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
