{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "#import pytorch_lightning as pl\n",
    "import lightning.pytorch as pl\n",
    "import torchmetrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score, MulticlassF1Score\n",
    "from torchmetrics.classification.accuracy import Accuracy, BinaryAccuracy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "#import pytorch_lightning.callbacks.\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.lr_monitor import LearningRateMonitor\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from resnet1d import ResNet1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\n",
    "    \"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./saved_models/ConvNets/\"\n",
    "\n",
    "\n",
    "# Function for setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "task = 'multiclass'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест на работоспособность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test beat shape (1, 12, 500)\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_beat = np.load('./transformed_train/00269_hr_n1.npy')\n",
    "kernel_size = 16\n",
    "stride = 2\n",
    "n_block = 48\n",
    "downsample_gap = 6\n",
    "increasefilter_gap = 12\n",
    "model = ResNet1D(\n",
    "    in_channels=12, \n",
    "    base_filters=16, # 64 for ResNet1D, 352 for ResNeXt1D\n",
    "    kernel_size=16, \n",
    "    stride=2, \n",
    "    groups=1, \n",
    "    n_block=12, \n",
    "    n_classes=1) \n",
    "\n",
    "\n",
    "test_beat = test_beat.reshape((1,12,-1))\n",
    "test_y = torch.tensor([[1.]])\n",
    "criterion = nn.BCELoss()\n",
    "print(\"test beat shape\", test_beat.shape)\n",
    "res= model(torch.from_numpy(test_beat).float())\n",
    "print(res.shape)\n",
    "criterion(res, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DatasetECG(Dataset):\n",
    "    def __init__(self, annotations_file, signals_dir):\n",
    "        \"\"\"\n",
    "        annotantions_file - path to the annotations dataframe. \n",
    "                            First column should be name of the record, second - strat_fold then labels \n",
    "        \n",
    "        signals_dir - path to the directory with transformed signals\n",
    "        \"\"\"\n",
    "        self.signals_labels = pd.read_csv(annotations_file)\n",
    "        #self.signals_labels = self.signals_labels[self.signals_labels[\"норма\"] != 1]\n",
    "        self.signals_dir = signals_dir \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signals_path = os.path.join(self.signals_dir, self.signals_labels.iloc[idx, 0]+ \".npy\")\n",
    "        signal = np.load(signals_path).astype(np.float32)        \n",
    "\n",
    "        # iloc[idx, 2:] 2 is because first column is a record name\n",
    "        # label = \"\".join(self.signals_labels.iloc[idx, 2:].values.astype(str).tolist())\n",
    "        labels = torch.from_numpy(self.signals_labels.iloc[idx, 2:].values.astype(int)).float()\n",
    "        if(task=='multiclass'):\n",
    "            labels = labels.argmax()\n",
    "        # label = self.targets.index(label)\n",
    "        # encoded_label = torch.zeros(13)\n",
    "        # encoded_label[label] = 1\n",
    "        return signal, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_TRAIN = './transformed_train2/'\n",
    "PREFIX_VAL ='./transformed_train/'\n",
    "\n",
    "train_dataset = DatasetECG(\"./train_annotations.csv\", PREFIX_TRAIN)\n",
    "val_dataset = DatasetECG(\"./val_annotations.csv\", PREFIX_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01595599, -0.01452019, -0.01285886, ..., -0.05533369,\n",
       "         -0.05917533, -0.05846827],\n",
       "        [ 0.00149945,  0.0019128 ,  0.0026792 , ..., -0.03774664,\n",
       "         -0.03252999, -0.02398809],\n",
       "        [ 0.00999824,  0.00886223,  0.00809438, ...,  0.00065544,\n",
       "         -0.00274447, -0.00584236],\n",
       "        ...,\n",
       "        [-0.1298285 , -0.12982513, -0.12974711, ..., -0.04617563,\n",
       "         -0.0457119 , -0.04531983],\n",
       "        [-0.10032634, -0.10036746, -0.10019438, ..., -0.04906217,\n",
       "         -0.04845833, -0.04787983],\n",
       "        [-0.06980778, -0.07076729, -0.07136829, ..., -0.0260726 ,\n",
       "         -0.02434688, -0.02278278]], dtype=float32),\n",
       " tensor(6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True) #, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False) #, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Lightning_ResNet1D(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams, model_class=ResNet1D, task=\"MULTILABEL\"):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = model_class(**model_hparams)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        self.train_score = F1Score(task=task, num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.val_score = MulticlassF1Score(task=task, num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.test_score = F1Score(task=task, num_labels=model_hparams[\"n_classes\"], num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.val_acc = Accuracy(task=task, num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        self.train_acc = Accuracy(task=task, num_labels=model_hparams[\"n_classes\"], num_classes=model_hparams[\"n_classes\"], top_k=1)\n",
    "        \n",
    "\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 12, 500), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here\n",
    "            # for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer: \"{self.hparams.optimizer_name}\"'\n",
    "\n",
    "        # We will reduce the learning rate by 0.1 every milestone\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[35,65, 115, 150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        self.model.train()\n",
    "        imgs, labels = batch\n",
    "        labels = np.squeeze(labels)\n",
    "        preds = np.squeeze(self.model(imgs))\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        #if len(preds.shape) < 2:\n",
    "        # print(preds.shape, labels.shape)\n",
    "        if False:\n",
    "            preds = preds.argmax(axis=1)\n",
    "            labels = labels.to(torch.int).argmax(axis=1)\n",
    "            \n",
    "        self.train_acc(preds, labels.to(torch.int))\n",
    "\n",
    "        self.train_score(preds, labels.to(torch.int))\n",
    "        # print(preds, labels.to(torch.int))\n",
    "        # print(preds.argmax(axis=1), labels.to(torch.int).argmax(axis=1))\n",
    "        self.log(\"train_f1_score\", self.train_score)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss  \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.model.eval()\n",
    "        imgs, labels = batch\n",
    "        labels = np.squeeze(labels)\n",
    "        preds = np.squeeze(self.model(imgs))\n",
    "\n",
    "        #preds = preds.view(1, -1)\n",
    "        #labels = labels.view(1, -1)\n",
    "        # print(torch.round(preds, decimals=2))\n",
    "        #if len(preds.shape) < 2:\n",
    "        #    preds = preds.view(-1, 1, -1)\n",
    "        #    labels = labels.view(1, -1)\n",
    "        # print(torch.round(preds, decimals=2))\n",
    "        # print(torch.round(labels, decimals=2))\n",
    "        # print(preds)\n",
    "        # print(labels)\n",
    "        self.val_acc(preds, labels.to(torch.int))\n",
    "        # print(preds)\n",
    "        # print(labels)\n",
    "        # print(preds.shape, labels.shape)\n",
    "        # print(preds.argmax(axis=1), labels.to(torch.int).argmax(axis=1))\n",
    "        self.val_score(preds, labels.to(torch.int))\n",
    "        self.log(\"val_f1_score\", self.val_score)\n",
    "        self.log(\"val_acc\", self.val_acc)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        preds = np.squeeze(self(batch))\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model_class=ResNet1D,num_epochs=None, train_continue = True, save_name=None, pretrained_filename=\"\", model_hparams=None, optimizer_hparams=None, optimizer_name=None, task=None):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    curr_model_save_path = os.path.join(CHECKPOINT_PATH, save_name)\n",
    "    trainer = pl.Trainer(\n",
    "        check_val_every_n_epoch=2,\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),  # Where to save models\n",
    "        # We run on a single GPU (if possible)\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        # How many epochs to train for if no patience is set\n",
    "        max_epochs=num_epochs,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                mode=\"max\", monitor=\"val_f1_score\", save_top_k=2,\n",
    "            ), \n",
    "            EarlyStopping(monitor=\"val_f1_score\", mode=\"max\", patience=15),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],  # Log learning rate every epoch\n",
    "    ) \n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = Lightning_ResNet1D.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        if(pretrained_filename!=\"\"):\n",
    "            print(\"FAILED TO LOAD A MODEL\")\n",
    "            return\n",
    "        # L.seed_everything(42)  # To be reproducable\n",
    "        if train_continue:\n",
    "            default_root_dir = os.path.join(CHECKPOINT_PATH, save_name) \n",
    "            default_root_dir = os.path.join(default_root_dir, \"lightning_logs\")\n",
    "            continue_path = os.path.join(default_root_dir, os.listdir(default_root_dir)[-1])\n",
    "            continue_path = os.path.join(continue_path, \"checkpoints\")\n",
    "            continue_path = os.path.join(continue_path, os.listdir(continue_path)[-1])\n",
    "\n",
    "\n",
    "        model = Lightning_ResNet1D(model_name=model_name, model_class=model_class,model_hparams=model_hparams, \n",
    "                                   optimizer_hparams=optimizer_hparams, optimizer_name=optimizer_name, task=task)\n",
    "        if train_continue:\n",
    "            trainer.fit(model, train_loader, val_loader, ckpt_path=continue_path)\n",
    "        else:\n",
    "            trainer.fit(model, train_loader, val_loader,)\n",
    "        model = Lightning_ResNet1D.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )  # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.validate(model, dataloaders=val_loader, verbose=False)\n",
    "    result = {\"val_acc\": val_result[0][\"val_acc\"], \"val_f1_score\": val_result[0][\"val_f1_score\"]}\n",
    "    \n",
    "    \n",
    "    return model, result, curr_model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params | In sizes     | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | ResNet1D           | 653 K  | [1, 12, 500] | [1, 7]   \n",
      "1 | loss_module | CrossEntropyLoss   | 0      | ?            | ?        \n",
      "2 | train_score | MulticlassF1Score  | 0      | ?            | ?        \n",
      "3 | val_score   | MulticlassF1Score  | 0      | ?            | ?        \n",
      "4 | test_score  | MulticlassF1Score  | 0      | ?            | ?        \n",
      "5 | val_acc     | MulticlassAccuracy | 0      | ?            | ?        \n",
      "6 | train_acc   | MulticlassAccuracy | 0      | ?            | ?        \n",
      "------------------------------------------------------------------------------\n",
      "653 K     Trainable params\n",
      "0         Non-trainable params\n",
      "653 K     Total params\n",
      "2.614     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f090bf82426444bbcee393340586ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6c6a1e1be642bd8e45099bef270850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f893ea3ada4947b68136eb6c546ed911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9929ead189824f4facad216484f87415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb16cfac5c74897bc9e245856c01fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbde51626d284afd8b1de4c0946671c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240691ffce444563bddff75640e1ea3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd11573ee734613b8505eb30e623d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518f12629c244f21844982473b292394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292f5b976cd34ce0be617611a0302f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f833b6b36844e6a8b6e0c6378802e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157ea938931b4478adbb7727a0100942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619939adec7f417c9e9b1060aefb1006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126e23223ca34425a902004b24b60a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad30c63d0acb4cf082ea4ff6cbdb473e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dcef2619da4c80aa29f4854b3039e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2a3a818be0406fb3cf214012add6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8fb9a1219c4f8a996067f2078699f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdae06243bde4caeb042527d29618fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21e96ed7e45422c999be9878718a4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22100da0ae07413cbce1e20f7791e986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd52b38dc0549979ada56f919f166ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96cced187e241debf562c14c23014d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5554068c7ae04e6c91ad6d06d7442126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8406c0e4dbba427185ff7cfff9aeab02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e2dcf8cd9b4fa8ba12fab63ce43e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dfd5a5605443949b915e64a5578d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f229621a60454d90f74863c8a59d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# pretrained_filename=\"saved_models/ConvNets/ResNet1D_denoising_level2/lightning_logs/version_3/checkpoints/epoch=63-step=23104.ckpt\",     \n",
    "#удалить аргумент pretrained filename, для тренировки заново\n",
    "resnet_model, resnet_results, curr_model_save_path = train_model(\n",
    "    train_continue=False,\n",
    "    num_epochs=50,\n",
    "    #pretrained_filename=\"saved_models/ConvNets/Final_fixed_val_added_norm/lightning_logs/version_0/checkpoints/epoch=31-step=65824.ckpt\",     \n",
    "    model_name=\"ResNet1D_v2\",\n",
    "    model_class=ResNet1D,\n",
    "    save_name=\"Final_added_augs\", \n",
    "    model_hparams={\"n_classes\": 7, \"base_filters\": 16, \"kernel_size\": 16, \"stride\": 2, \"groups\": 1, \"n_block\": 12, \"in_channels\": 12},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 0.0001,  \"weight_decay\": 1e-4},\n",
    "    task=\"multiclass\"\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_acc': 0.6364899277687073, 'val_f1_score': 0.2566266357898712}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import mode\n",
    "\n",
    "resnet_model.eval()\n",
    "\n",
    "def predict(beat_filename):\n",
    "    test_beat = np.load(beat_filename).astype(np.float32) \n",
    "    test_beat = test_beat.reshape((1,12,-1))\n",
    "    res = resnet_model(torch.from_numpy(test_beat).float())\n",
    "    return res.detach().numpy()\n",
    "\n",
    "def run_test_predicts(curr_model_save_path, treshhold=0.5):\n",
    "    df_og = pd.read_csv(\"./train/train_meta.csv\")\n",
    "    test_annotations = pd.read_csv(\"./val_annotations.csv\")\n",
    "    test_annotations.drop_duplicates(inplace=True)\n",
    "    preds = {}\n",
    "    for name in tqdm(test_annotations[\"new_name\"]):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        pred = np.argmax(predict(\"./transformed_train/\"+name+\".npy\"))\n",
    "        preds[record_name].append(pred)\n",
    "\n",
    "    preds_most_freq = {}\n",
    "    for name, preds in preds.items(): \n",
    "        most_freq_pred = np.argmax(np.bincount(preds))   \n",
    "        preds_most_freq[name] = most_freq_pred\n",
    "\n",
    "    df_og[\"predict\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "    return df_og, preds_most_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e6f3987bb6483a87dccdf662c1f0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_res, d = run_test_predicts(curr_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>record_name</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18792.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>00009_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18153.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>00052_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16063.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>00057_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14751.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00209_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15351.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>00247_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>20990.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21744_hr</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>9993.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21774_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>10162.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21795_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>11197.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21825_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>11905.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21831_hr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id   age  sex  height  weight record_name  predict\n",
       "0        18792.0  55.0    0     NaN    70.0    00009_hr      6.0\n",
       "3        18153.0  35.0    0     NaN    82.0    00052_hr      6.0\n",
       "4        16063.0  26.0    0     NaN    93.0    00057_hr      6.0\n",
       "23       14751.0  37.0    0     NaN     NaN    00209_hr      6.0\n",
       "27       15351.0  25.0    0     NaN    75.0    00247_hr      6.0\n",
       "...          ...   ...  ...     ...     ...         ...      ...\n",
       "2091     20990.0  37.0    1     NaN     NaN    21744_hr      0.0\n",
       "2094      9993.0  74.0    0     NaN     NaN    21774_hr      6.0\n",
       "2097     10162.0  68.0    0     NaN     NaN    21795_hr      6.0\n",
       "2098     11197.0  59.0    0     NaN     NaN    21825_hr      6.0\n",
       "2099     11905.0  55.0    1     NaN     NaN    21831_hr      6.0\n",
       "\n",
       "[420 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res = test_res[~test_res.predict.isna()]\n",
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>норма</th>\n",
       "      <th>передний</th>\n",
       "      <th>перегородочный</th>\n",
       "      <th>нижний</th>\n",
       "      <th>передне-перегородочный</th>\n",
       "      <th>передне-боковой</th>\n",
       "      <th>боковой</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     норма  передний  перегородочный  нижний  передне-перегородочный  \\\n",
       "0        1         0               0       0                       0   \n",
       "1        1         0               0       0                       0   \n",
       "2        1         0               0       0                       0   \n",
       "3        1         0               0       0                       0   \n",
       "4        1         0               0       0                       0   \n",
       "..     ...       ...             ...     ...                     ...   \n",
       "415      0         0               1       0                       0   \n",
       "416      1         0               0       0                       0   \n",
       "417      1         0               0       0                       0   \n",
       "418      1         0               0       0                       0   \n",
       "419      1         0               0       0                       0   \n",
       "\n",
       "     передне-боковой  боковой  \n",
       "0                  0        0  \n",
       "1                  0        0  \n",
       "2                  0        0  \n",
       "3                  0        0  \n",
       "4                  0        0  \n",
       "..               ...      ...  \n",
       "415                0        0  \n",
       "416                0        0  \n",
       "417                0        0  \n",
       "418                0        0  \n",
       "419                0        0  \n",
       "\n",
       "[420 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = pd.DataFrame(test_res.predict.tolist())\n",
    "\n",
    "label2pred = {\"перегородочный\":0, \"передний\":1, \"боковой\":2, \"передне-боковой\":3, \"передне-перегородочный\":4, \"нижний\":5, \"норма\":6}\n",
    "pred2label = {v:k for k, v in label2pred.items()}\n",
    "\n",
    "unique_values = predicts[0].unique() \n",
    "unique_values = np.append(unique_values, 2)\n",
    "for value in unique_values:\n",
    "    column_name = pred2label[value]\n",
    "    predicts[column_name] = (predicts[0] == value).astype(int)\n",
    "predicts = predicts.drop(columns=[0])\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_annotations = pd.read_csv(\"./train/train_gts_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res2 = test_res.merge(val_annotations, on=\"record_name\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>record_name</th>\n",
       "      <th>predict</th>\n",
       "      <th>перегородочный</th>\n",
       "      <th>передний</th>\n",
       "      <th>боковой</th>\n",
       "      <th>передне-боковой</th>\n",
       "      <th>передне-перегородочный</th>\n",
       "      <th>нижний</th>\n",
       "      <th>норма</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18792.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>00009_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18153.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>00052_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16063.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>00057_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14751.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00209_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15351.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>00247_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>20990.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21744_hr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>9993.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21774_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>10162.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21795_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>11197.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21825_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>11905.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21831_hr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id   age  sex  height  weight record_name  predict  \\\n",
       "0       18792.0  55.0    0     NaN    70.0    00009_hr      6.0   \n",
       "1       18153.0  35.0    0     NaN    82.0    00052_hr      6.0   \n",
       "2       16063.0  26.0    0     NaN    93.0    00057_hr      6.0   \n",
       "3       14751.0  37.0    0     NaN     NaN    00209_hr      6.0   \n",
       "4       15351.0  25.0    0     NaN    75.0    00247_hr      6.0   \n",
       "..          ...   ...  ...     ...     ...         ...      ...   \n",
       "415     20990.0  37.0    1     NaN     NaN    21744_hr      0.0   \n",
       "416      9993.0  74.0    0     NaN     NaN    21774_hr      6.0   \n",
       "417     10162.0  68.0    0     NaN     NaN    21795_hr      6.0   \n",
       "418     11197.0  59.0    0     NaN     NaN    21825_hr      6.0   \n",
       "419     11905.0  55.0    1     NaN     NaN    21831_hr      6.0   \n",
       "\n",
       "     перегородочный  передний  боковой  передне-боковой  \\\n",
       "0                 0         0        0                0   \n",
       "1                 0         0        0                0   \n",
       "2                 0         0        0                0   \n",
       "3                 0         0        0                0   \n",
       "4                 0         0        0                0   \n",
       "..              ...       ...      ...              ...   \n",
       "415               0         0        0                0   \n",
       "416               0         0        0                0   \n",
       "417               0         0        0                0   \n",
       "418               0         0        0                0   \n",
       "419               0         0        0                0   \n",
       "\n",
       "     передне-перегородочный  нижний  норма  \n",
       "0                         0       0      1  \n",
       "1                         0       0      1  \n",
       "2                         0       0      1  \n",
       "3                         0       0      1  \n",
       "4                         0       0      1  \n",
       "..                      ...     ...    ...  \n",
       "415                       0       0      1  \n",
       "416                       0       0      1  \n",
       "417                       0       0      1  \n",
       "418                       0       0      1  \n",
       "419                       0       0      1  \n",
       "\n",
       "[420 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "перегородочный F1 0.10810810810810811\n",
      "передний F1 0.06666666666666667\n",
      "боковой F1 0.0\n",
      "передне-боковой F1 0.16666666666666666\n",
      "передне-перегородочный F1 0.23376623376623373\n",
      "нижний F1 0.40449438202247195\n",
      "норма F1 0.8157894736842105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('TOTAL', 0.2564987901306225)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "summs = 0\n",
    "for i, column in enumerate([\"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\", \"норма\"]):\n",
    "    print(column, \"F1\", f1_score(test_res2[column], predicts[column]))\n",
    "    summs += f1_score(test_res2[column], predicts[column])\n",
    "\"TOTAL\", summs / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_name                  00269_hr_n000269_hr_n100269_hr_n200269_hr_n300...\n",
       "target                                                                97088\n",
       "перегородочный                                                       2624.0\n",
       "передний                                                             2624.0\n",
       "боковой                                                                 0.0\n",
       "передне-боковой                                                      5248.0\n",
       "передне-перегородочный                                               2624.0\n",
       "нижний                                                               1312.0\n",
       "норма                                                                  1312\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./train_annotations.csv\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_res[~test_res.predict.isna()][\"predict\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict тренировочных данных и тестовых данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс еще не доделал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (275528591.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [24]\u001b[0;36m\u001b[0m\n\u001b[0;31m    from augmentation import\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#from augmentation import \n",
    "class Predictor():\n",
    "    def __init__(self,curr_model_save_path, test_df_path=\"./test/test_meta.csv\",  tta=True) -> None:\n",
    "        \"\"\"\n",
    "        curr_model_save_path: example: \n",
    "        \"\"\"\n",
    "\n",
    "        resnet_model.eval()\n",
    "        self.curr_model_save_path = curr_model_save_path\n",
    "        self.test_df_path = test_df_path\n",
    "    \n",
    "    def TTA():\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _predict(self, beat_filename):\n",
    "        test_beat = np.load(beat_filename).astype(np.float32) \n",
    "        test_beat = test_beat.reshape((1,12,-1))\n",
    "        res = resnet_model(torch.from_numpy(test_beat).float())\n",
    "        return res.detach().numpy()\n",
    "\n",
    "    def run_test_predicts_multiclass(self):\n",
    "        df_og = pd.read_csv(self.test_df_path)\n",
    "        test_annotations = pd.read_csv(\"./transformed_test_df.csv\")\n",
    "        preds = {}\n",
    "        for name in tqdm(test_annotations[\"new_name\"].values):\n",
    "            record_name = name[:name.rfind(\"_\")]\n",
    "            if record_name not in preds:\n",
    "                preds[record_name] = []\n",
    "            pred = np.argmax(predict(\"./transformed_test/\"+name+\".npy\"))\n",
    "            preds[record_name].append(pred)\n",
    "        \n",
    "        preds_most_freq = {}\n",
    "        for name, preds in preds.items(): \n",
    "            most_freq_pred = np.argmax(np.bincount(preds))   \n",
    "            preds_most_freq[name] = most_freq_pred\n",
    "\n",
    "        df_og[\"predict\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "\n",
    "        label2pred = {\"перегородочный\":0, \"передний\":1, \"боковой\":2, \"передне-боковой\":3, \"передне-перегородочный\":4, \"нижний\":5, \"норма\":6}\n",
    "        pred2label = {v:k for k, v in label2pred.items()}\n",
    "        \n",
    "        unique_values = df_og['predict'].unique() \n",
    "        unique_values = np.append(unique_values, 2)\n",
    "        for value in unique_values:\n",
    "            column_name = pred2label[value]\n",
    "            df_og[column_name] = (df_og['predict'] == value).astype(int)\n",
    "\n",
    "        df_og[\"target\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "        \n",
    "        save_path = os.path.join(curr_model_save_path, \"predicted_test.csv\")\n",
    "        df_og.to_csv(save_path)\n",
    "        df_og.to_csv(\"./predicted_test.csv\")\n",
    "        print(\"Соотношение предсказанных классов:\")\n",
    "        display(df_og['target'].apply(round).value_counts(normalize=True))\n",
    "        return df_og\n",
    "\n",
    "    def run_test_predicts_multilabel(self):\n",
    "        df_og = pd.read_csv(self.test_df_path)\n",
    "        test_annotations = pd.read_csv(\"./transformed_test_df.csv\")\n",
    "        preds = {}\n",
    "        for name in tqdm(test_annotations[\"new_name\"].values):\n",
    "            record_name = name[:name.rfind(\"_\")]\n",
    "            if record_name not in preds:\n",
    "                preds[record_name] = []\n",
    "            pred = np.argmax(predict(\"./transformed_test/\"+name+\".npy\"))\n",
    "            preds[record_name].append(pred)\n",
    "\n",
    "        #TODO: dopisat'\n",
    "\n",
    "        preds_median = {}\n",
    "        df_og[\"target\"] = df_og[\"record_name\"].map(preds_median)\n",
    "        \n",
    "        save_path = os.path.join(curr_model_save_path, \"predicted_test.csv\")\n",
    "        df_og.to_csv(save_path)\n",
    "        df_og.to_csv(\"./predicted_test.csv\")\n",
    "        print(\"Соотношение предсказанных классов:\")\n",
    "        display(df_og['target'].apply(round).value_counts(normalize=True))\n",
    "        return df_og\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import mode\n",
    "\n",
    "resnet_model.eval()\n",
    "\n",
    "def predict(beat_filename):\n",
    "    test_beat = np.load(beat_filename).astype(np.float32) \n",
    "    test_beat = test_beat.reshape((1,12,-1))\n",
    "    res = resnet_model(torch.from_numpy(test_beat).float())\n",
    "    return res.detach().numpy()\n",
    "\n",
    "def run_test_predicts(curr_model_save_path):\n",
    "    df_og = pd.read_csv(\"./test/test_meta.csv\")\n",
    "    test_annotations = pd.read_csv(\"./transformed_test_df.csv\")\n",
    "    preds = {}\n",
    "    for name in tqdm(test_annotations[\"new_name\"].values):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        pred = np.argmax(predict(\"./transformed_test/\"+name+\".npy\"))\n",
    "        preds[record_name].append(pred)\n",
    "    \n",
    "    preds_most_freq = {}\n",
    "    for name, preds in preds.items(): \n",
    "        most_freq_pred = np.argmax(np.bincount(preds))   \n",
    "        preds_most_freq[name] = most_freq_pred\n",
    "\n",
    "    df_og[\"predict\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "\n",
    "    #print(np.round(np.array(preds[\"00127_hr\"]).mean(axis=0), 2))\n",
    "    #preds_median = {k: np.array(v).mean(axis=0) > 0.5 for k,v in preds.items()}\n",
    "    #df_og[\"predict\"] = df_og[\"record_name\"].map(preds_median)\n",
    "    label2pred = {\"перегородочный\":0, \"передний\":1, \"боковой\":2, \"передне-боковой\":3, \"передне-перегородочный\":4, \"нижний\":5, \"норма\":6}\n",
    "    pred2label = {v:k for k, v in label2pred.items()}\n",
    "    \n",
    "    unique_values = df_og['predict'].unique() \n",
    "    unique_values = np.append(unique_values, 2)\n",
    "    for value in unique_values:\n",
    "        column_name = pred2label[value]\n",
    "        df_og[column_name] = (df_og['predict'] == value).astype(int)\n",
    "\n",
    "    #preds_median = {k: np.array(v).mean(axis=0).argmax() for k,v in preds.items()}\n",
    "    df_og[\"target\"] = df_og[\"record_name\"].map(preds_most_freq)\n",
    "    \n",
    "    save_path = os.path.join(curr_model_save_path, \"predicted_test.csv\")\n",
    "    df_og.to_csv(save_path)\n",
    "    df_og.to_csv(\"./predicted_test.csv\")\n",
    "    print(\"Соотношение предсказанных классов:\")\n",
    "    display(df_og['target'].apply(round).value_counts(normalize=True))\n",
    "    return df_og\n",
    "\n",
    "def preds_train_df(curr_model_save_path):\n",
    "    df = pd.read_csv(\"./transformed_df.csv\")\n",
    "    preds = {}\n",
    "    for name in tqdm(df[\"new_name\"].values):\n",
    "        record_name = name[:name.rfind(\"_\")]\n",
    "        if record_name not in preds:\n",
    "            preds[record_name] = []\n",
    "        preds[record_name].append(predict(\"./transformed_train/\"+name+\".npy\"))\n",
    "    \n",
    "    df_og = pd.read_csv(\"../task_final/train/train_gts_final.csv\")\n",
    "    \n",
    "    preds_median = {k:np.median(np.array(v)) for k,v in preds.items()}\n",
    "    df_og['predict'] = df_og[\"record_name\"].map(preds_median)\n",
    "    save_path = os.path.join(curr_model_save_path, \"predicted_train.csv\")\n",
    "    df_og.to_csv(save_path)\n",
    "    df_og.to_csv(\"./predicted_train.csv\")\n",
    "    print(\"Соотношение предсказанных классов:\")\n",
    "    display(df_og['predict'].apply(round).value_counts(normalize=True))\n",
    "    return preds, df_og\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_submit = pd.read_csv(\"old_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47280f03f8a44431ba99d89da94c0b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение предсказанных классов:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6    0.625835\n",
       "5    0.120267\n",
       "4    0.109131\n",
       "0    0.084633\n",
       "1    0.035635\n",
       "3    0.024499\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_res = run_test_predicts(curr_model_save_path)\n",
    "# preds, df_og = preds_train_df(curr_model_save_path)\n",
    "\n",
    "one_hot_enc = np.zeros((449, 6))\n",
    "for i in range(449):\n",
    "    one_hot_enc[i] = test_res[\"predict\"].iloc[i] * 1 + [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_enc = np.zeros((449, 6))\n",
    "for i in range(449):\n",
    "    one_hot_enc[i] = test_res[\"predict\"].iloc[i] * 1 + [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6., 6., 6., 6., 6.],\n",
       "       [6., 6., 6., 6., 6., 6.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [3., 3., 3., 3., 3., 3.],\n",
       "       [6., 6., 6., 6., 6., 6.],\n",
       "       [6., 6., 6., 6., 6., 6.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test_res[[\"перегородочный\",\"передний\",\"боковой\",\"передне-боковой\",\"передне-перегородочный\",\"нижний\",\"норма\",\"record_name\"]]\n",
    "#submit = pd.read_csv('saved_models/ConvNets/two_models/submit.csv')\n",
    "sample = pd.read_csv(\"./sample.csv\")\n",
    "submit = sample.merge(submit, on=\"record_name\", how=\"left\")\n",
    "submit = submit[[\"record_name\", \"перегородочный\",\"передний\",\"боковой\",\"передне-боковой\",\"передне-перегородочный\",\"нижний\",\"норма\"]]\n",
    "submit.to_csv(f\"{curr_model_save_path}/submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'old_submit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb Cell 35\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m onehot_df[\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_res[\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m subm_df \u001b[39m=\u001b[39m test_res\u001b[39m.\u001b[39mmerge(onehot_df, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m subm_df \u001b[39m=\u001b[39m subm_df\u001b[39m.\u001b[39mmerge(old_submit, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecord_name\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m subm_df[\u001b[39m\"\u001b[39m\u001b[39mнорма\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m subm_df[\u001b[39m\"\u001b[39m\u001b[39mmyocard\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mперегородочный\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mпередний\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mбоковой\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mпередне-боковой\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/biba/Documents/programming/aiijc/AIIJC23_Medtech_bobs/platform_solve/model_training.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mпередне-перегородочный\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mнижний\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'old_submit' is not defined"
     ]
    }
   ],
   "source": [
    "onehot_df = pd.DataFrame(one_hot_enc, columns=[\"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\"])\n",
    "onehot_df[\"record_name\"] = test_res[\"record_name\"]\n",
    "subm_df = test_res.merge(onehot_df, on=\"record_name\", how=\"left\")\n",
    "subm_df = subm_df.merge(old_submit, on=\"record_name\", how=\"left\")\n",
    "subm_df[\"норма\"] = subm_df[\"myocard\"].map(lambda x: 0 if x == 1 else 1)\n",
    "for column in [\"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\"]:\n",
    "    subm_df[column] = subm_df['myocard'] & subm_df[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df[[\"record_name\", \"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\", \"норма\"]].to_csv(\"submit.csv\", index=False)\n",
    "subm_df[[\"record_name\", \"перегородочный\", \"передний\", \"боковой\", \"передне-боковой\", \n",
    "                             \"передне-перегородочный\", \"нижний\", \"норма\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание всех тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean = {k:(sum(v)/len(v)) for k,v in preds.items()}\n",
    "preds_median = {k:np.median(np.array(v)) for k,v in preds.items()}\n",
    "preds_max= {k:np.argmax(np.array(v)) for k,v in preds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(preds, df_og):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "\n",
    "    for k, v in preds.items():\n",
    "        predicted_class = round(v)\n",
    "        actual_class = df_og[df_og[\"record_name\"] == k][\"myocard\"].values[0]\n",
    "        \n",
    "        if actual_class == 1 and predicted_class == 1:\n",
    "            tp += 1\n",
    "        elif actual_class == 0 and predicted_class == 0:\n",
    "            tn += 1\n",
    "        elif actual_class == 0 and predicted_class == 1:\n",
    "            fp += 1\n",
    "        elif actual_class == 1 and predicted_class == 0:\n",
    "            fn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    print(\"accuracy\", (tp + tn)/len(preds))\n",
    "    print(\"true positive rate, recall\", (tp/(tp+fn)))\n",
    "    print(\"true negative rate\", tnr)\n",
    "    print(\"f1_score\", 2*(precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(preds_mean, df_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(preds_median, df_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(preds_max, df_og)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
